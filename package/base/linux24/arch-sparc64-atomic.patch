
Fix atomic.S on sparc64 for correct behaviour with gcc-3.4.

  David S. Miller, Hugh Dickins, Rene Rebe et al

===== arch/sparc64/lib/atomic.S 1.5 vs edited =====
--- 1.5/arch/sparc64/lib/atomic.S	2004-08-26 14:34:13 -07:00
+++ edited/arch/sparc64/lib/atomic.S	2005-02-01 11:16:32 -08:00
@@ -7,8 +7,22 @@
 #include <asm/asi.h>
 
 	.text
-	.align	64
 
+	/* We use these stubs for the uncommon case
+	 * of contention on the atomic value.  This is
+	 * so that we can keep the main fast path 8
+	 * instructions long and thus fit into a single
+	 * L2 cache line.
+	 */
+__atomic_add_membar:
+	ba,pt	%xcc, __atomic_add
+	 membar	#StoreLoad | #StoreStore
+
+__atomic_sub_membar:
+	ba,pt	%xcc, __atomic_sub
+	 membar	#StoreLoad | #StoreStore
+
+	.align	64
 	.globl	__atomic_add
 	.type	__atomic_add,#function
 __atomic_add: /* %o0 = increment, %o1 = atomic_ptr */
@@ -16,10 +30,10 @@
 	add	%g5, %o0, %g7
 	cas	[%o1], %g5, %g7
 	cmp	%g5, %g7
-	bne,pn	%icc, __atomic_add
-	 membar	#StoreLoad | #StoreStore
+	bne,pn	%icc, __atomic_add_membar
+	 add	%g7, %o0, %g7
 	retl
-	 add	%g7, %o0, %o0
+	 sra	%g7, 0, %o0
 	.size	__atomic_add, .-__atomic_add
 
 	.globl	__atomic_sub
@@ -29,10 +43,10 @@
 	sub	%g5, %o0, %g7
 	cas	[%o1], %g5, %g7
 	cmp	%g5, %g7
-	bne,pn	%icc, __atomic_sub
-	 membar	#StoreLoad | #StoreStore
+	bne,pn	%icc, __atomic_sub_membar
+	 sub	%g7, %o0, %g7
 	retl
-	 sub	%g7, %o0, %o0
+	 sra	%g7, 0, %o0
 	.size	__atomic_sub, .-__atomic_sub
 
 	.globl	__atomic64_add
