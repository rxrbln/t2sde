-- --- T2-COPYRIGHT-NOTE-BEGIN ---
-- This copyright note is auto-generated by ./scripts/Create-CopyPatch.
-- 
-- T2 SDE: package/.../sam/sam/tokenize.lua
-- Copyright (C) 2006 The T2 SDE Project
-- 
-- More information can be found in the files COPYING and README.
-- 
-- This program is free software; you can redistribute it and/or modify
-- it under the terms of the GNU General Public License as published by
-- the Free Software Foundation; version 2 of the License. A copy of the
-- GNU General Public License can be found in the file COPYING.
-- --- T2-COPYRIGHT-NOTE-END ---

-- TODO:
--   - function that decodes escape sequences

sam = sam or {}

-- sam.tokenize(some-string)
--   Extend string with a shell alike tokenizer.
--   This is a rather ugly code imo, a better solution
--   is welcome!
function sam.tokenize(str)
	local idx = {} -- list of indexes to split str

	-- parse thru all characters of the string
	-- and check for quotes and escaping
	local n = 0
	local esc = 0
	local quote = 0
	local last = ' '
	for c in string.gfind(str, ".") do
		n = n + 1
		
		if esc == 0 then
			if c == '\\' then
				esc = 1
			elseif c == '"' or c == "'" then
				if quote == 0 then
					quote = 1
					if last == ' ' then
						-- we found the start of a token
						table.insert(idx, n)
					end
				else 
					quote = 0
				end
			elseif quote == 0 then
				if c == ' ' or c == '\t' then
					if last ~= ' ' then
						-- we found the end of a token
						table.insert(idx, n-1)
					end
					c = ' '
				elseif last == ' ' then
					-- we found the start of a token
					table.insert(idx, n)
				end
			end
		else
			esc = 0
		end

		last = c
	end
	if #idx > 0 then
		-- closing token at end-of-line
		table.insert(idx, n)
	end

	-- assemble the tokens into a table
	local toks = {}
	n = 1
	while n < #idx do 
		table.insert(toks, string.sub(str, idx[n], idx[n+1]))
		n = n+2
	end
	
	return toks
end


