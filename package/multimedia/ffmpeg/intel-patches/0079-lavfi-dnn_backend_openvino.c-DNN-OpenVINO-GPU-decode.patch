# --- T2-COPYRIGHT-NOTE-BEGIN ---
# T2 SDE: package/*/ffmpeg/intel-patches/0079-lavfi-dnn_backend_openvino.c-DNN-OpenVINO-GPU-decode.patch
# Copyright (C) 2023 The T2 SDE Project
# 
# This Copyright note is generated by scripts/Create-CopyPatch,
# more information can be found in the files COPYING and README.
# 
# This patch file is dual-licensed. It is available under the license the
# patched project is licensed under, as long as it is an OpenSource license
# as defined at http://www.opensource.org/ (e.g. BSD, X11) or under the terms
# of the GNU General Public License version 2 as used by the T2 SDE.
# --- T2-COPYRIGHT-NOTE-END ---

From 9a85f4287ce06dc9a4121366b0f75ddc0a648fc5 Mon Sep 17 00:00:00 2001
From: Kizna1ver <jianyuliucsu@gmail.com>
Date: Tue, 13 Sep 2022 14:56:13 +0800
Subject: [PATCH 24/41] lavfi/dnn_backend_openvino.c: DNN OpenVINO GPU decode &
 inference support

---
 libavfilter/dnn/dnn_backend_openvino.c | 183 ++++++++++++++++++++-----
 1 file changed, 151 insertions(+), 32 deletions(-)

diff --git a/libavfilter/dnn/dnn_backend_openvino.c b/libavfilter/dnn/dnn_backend_openvino.c
index ca72071cc6..5378c16234 100644
--- a/libavfilter/dnn/dnn_backend_openvino.c
+++ b/libavfilter/dnn/dnn_backend_openvino.c
@@ -30,6 +30,10 @@
 #include "libavutil/opt.h"
 #include "libavutil/avstring.h"
 #include "libavutil/detection_bbox.h"
+#if CONFIG_VAAPI
+#include "libavutil/hwcontext.h"
+#include "libavutil/hwcontext_vaapi.h"
+#endif
 #include "../internal.h"
 #include "safe_queue.h"
 #include <c_api/ie_c_api.h>
@@ -54,6 +58,7 @@ typedef struct OVModel{
     ie_core_t *core;
     ie_network_t *network;
     ie_executable_network_t *exe_network;
+    ie_remote_context_t *va_context;
     SafeQueue *request_queue;   // holds OVRequestItem
     Queue *task_queue;          // holds TaskItem
     Queue *lltask_queue;     // holds LastLevelTaskItem
@@ -113,6 +118,85 @@ static int get_datatype_size(DNNDataType dt)
     }
 }
 
+#if CONFIG_VAAPI
+static int fill_vaapi_blob(OVModel *ov_model, TaskItem *task, OVRequestItem *request)
+{
+    // if we use vaapi as decoder hardware accelerator, output frame of decoder will be NV12 format.
+    IEStatusCode status;
+    ie_blob_t *nv12_blob = NULL;
+    unsigned int surface_id = (unsigned int)(uintptr_t)(task->in_frame->data[3]);
+    status = ie_blob_make_memory_nv12_from_va_surface(task->in_frame->height, task->in_frame->width, ov_model->va_context, surface_id, &nv12_blob);
+    if (status != OK) {
+        av_log(&ov_model->ctx, AV_LOG_ERROR, "Failed to make remote nv12 blob from surface_id of input frame.");
+        return DNN_GENERIC_ERROR;
+    }
+    // error will be raised if we using ie_infer_request_get_blob.
+    // so, only ie_infer_request_set_blob can be used to set input data.
+    status = ie_infer_request_set_blob(request->infer_request, task->input_name, nv12_blob);
+    if (status != OK) {
+        av_log(&ov_model->ctx, AV_LOG_ERROR, "Failed to set remote nv12 blob as input by input name.");
+        return DNN_GENERIC_ERROR;
+    }
+    return 0;
+}
+
+static int load_network_vaapi(OVModel *ov_model, const AVFrame* input_frame, const char *input_name)
+{
+    // for model loaded in vaapi, we should do all prepostprocess with ov CAPI.
+    IEStatusCode status;
+    AVBufferRef* hw_device_ctx = ov_model->model->filter_ctx->hw_device_ctx;
+    AVHWDeviceContext *hw_device_data = (AVHWDeviceContext *)hw_device_ctx ->data;
+    AVVAAPIDeviceContext *va_device_data = (AVVAAPIDeviceContext *)hw_device_data ->hwctx;
+    VADisplay display = va_device_data -> display;
+    input_shapes_t input_shapes;
+    ie_config_t config = {NULL, NULL, NULL};
+    OVContext *ctx = &ov_model->ctx;
+    status = ie_network_get_input_shapes(ov_model->network, &input_shapes);
+    if (status != OK) {
+        av_log(ctx, AV_LOG_ERROR, "Failed to get input shapes \n");
+        return DNN_GENERIC_ERROR;
+    }
+    for (int i = 0; i < input_shapes.shape_num; i++) {
+        // reshape input shapes to enable auto resize algorithm
+        input_shapes.shapes[i].shape.dims[0] = ctx->options.batch_size;
+        input_shapes.shapes[i].shape.dims[2] = input_frame->height;
+        input_shapes.shapes[i].shape.dims[3] = input_frame->width;
+    }
+    status = ie_network_reshape(ov_model->network, input_shapes);
+    if (status != OK) {
+        av_log(ctx, AV_LOG_ERROR, "Failed to reshape the input of network \n");
+        return DNN_GENERIC_ERROR;
+    }
+    ie_network_input_shapes_free(&input_shapes);
+
+    // Auto resize and convert color format in openvino preprocess
+    status |= ie_network_set_input_resize_algorithm(ov_model->network, input_name, RESIZE_BILINEAR);
+    status |= ie_network_set_input_layout(ov_model->network, input_name, NCHW);
+    status |= ie_network_set_input_precision(ov_model->network, input_name, U8);
+    // set input color format to NV12 to enable automatic input color format convert to bgr,
+    // if not use ie_network_set_color_format the input blob will keep its own color format.
+    status |= ie_network_set_color_format(ov_model->network, input_name, NV12);
+    if (status != OK) {
+        av_log(ctx, AV_LOG_ERROR, "Failed to set input infomation of network \n");
+        return DNN_GENERIC_ERROR;
+    }
+
+    config.name = "CLDNN_NV12_TWO_INPUTS";
+    config.value = "YES";
+    status = ie_make_shared_va_context(ov_model->core, "GPU", display, &ov_model->va_context, -1);
+    if (status != OK) {
+        av_log(ctx, AV_LOG_ERROR, "Failed to make va_context \n");
+        return DNN_GENERIC_ERROR;
+    }
+    status = ie_core_load_network_va(ov_model->core, ov_model->network, ov_model->va_context, &config, &ov_model->exe_network);
+    if (status != OK) {
+        av_log(ctx, AV_LOG_ERROR, "Failed to load network \n");
+        return DNN_GENERIC_ERROR;
+    }
+    return 0;
+}
+#endif
+
 static int fill_model_input_ov(OVModel *ov_model, OVRequestItem *request)
 {
     dimensions_t dims;
@@ -128,37 +212,52 @@ static int fill_model_input_ov(OVModel *ov_model, OVRequestItem *request)
     lltask = ff_queue_peek_front(ov_model->lltask_queue);
     av_assert0(lltask);
     task = lltask->task;
+    if (ov_model->va_context) {
+#if CONFIG_VAAPI
+        if (fill_vaapi_blob(ov_model, task, request) == DNN_GENERIC_ERROR) {
+            av_log(ctx, AV_LOG_ERROR, "Failed to fill va surface blob\n");
+            return DNN_GENERIC_ERROR;
+        }
+        // in vaapi, we used origin hwframe height and width as input.
+        input.height = task->in_frame->height;
+        input.width = task->in_frame->width;
+        input.channels = 2;
+        input.data = blob_buffer.buffer;
+        input.dt = DNN_UINT8;
+#endif
+    } else {
+        status = ie_infer_request_get_blob(request->infer_request, task->input_name, &input_blob);
+        if (status != OK) {
+            av_log(ctx, AV_LOG_ERROR, "Failed to get input blob with name %s\n", task->input_name);
+            return DNN_GENERIC_ERROR;
+        }
 
-    status = ie_infer_request_get_blob(request->infer_request, task->input_name, &input_blob);
-    if (status != OK) {
-        av_log(ctx, AV_LOG_ERROR, "Failed to get input blob with name %s\n", task->input_name);
-        return DNN_GENERIC_ERROR;
-    }
+        status |= ie_blob_get_dims(input_blob, &dims);
+        status |= ie_blob_get_precision(input_blob, &precision);
+        if (status != OK) {
+            ie_blob_free(&input_blob);
+            av_log(ctx, AV_LOG_ERROR, "Failed to get input blob dims/precision\n");
+            return DNN_GENERIC_ERROR;
+        }
 
-    status |= ie_blob_get_dims(input_blob, &dims);
-    status |= ie_blob_get_precision(input_blob, &precision);
-    if (status != OK) {
-        ie_blob_free(&input_blob);
-        av_log(ctx, AV_LOG_ERROR, "Failed to get input blob dims/precision\n");
-        return DNN_GENERIC_ERROR;
-    }
+        status = ie_blob_get_buffer(input_blob, &blob_buffer);
+        if (status != OK) {
+            ie_blob_free(&input_blob);
+            av_log(ctx, AV_LOG_ERROR, "Failed to get input blob buffer\n");
+            return DNN_GENERIC_ERROR;
+        }
 
-    status = ie_blob_get_buffer(input_blob, &blob_buffer);
-    if (status != OK) {
-        ie_blob_free(&input_blob);
-        av_log(ctx, AV_LOG_ERROR, "Failed to get input blob buffer\n");
-        return DNN_GENERIC_ERROR;
+        // DNNData is set to input format of origin model to enable openvino preprocess
+        input.height = dims.dims[2];
+        input.width = dims.dims[3];
+        input.channels = dims.dims[1];
+        input.data = blob_buffer.buffer;
+        input.dt = precision_to_datatype(precision);
+        // all models in openvino open model zoo use BGR as input,
+        // change to be an option when necessary.
+        input.order = DCO_BGR_PACKED;
     }
 
-    input.height = dims.dims[2];
-    input.width = dims.dims[3];
-    input.channels = dims.dims[1];
-    input.data = blob_buffer.buffer;
-    input.dt = precision_to_datatype(precision);
-    // all models in openvino open model zoo use BGR as input,
-    // change to be an option when necessary.
-    input.order = DCO_BGR_PACKED;
-
     for (int i = 0; i < ctx->options.batch_size; ++i) {
         lltask = ff_queue_pop_front(ov_model->lltask_queue);
         if (!lltask) {
@@ -167,6 +266,9 @@ static int fill_model_input_ov(OVModel *ov_model, OVRequestItem *request)
         request->lltasks[i] = lltask;
         request->lltask_count = i + 1;
         task = lltask->task;
+        // if full gpu pipeline enabled, preprocss shouldn't be in software.
+        if (ov_model->va_context)
+            break;
         switch (ov_model->model->func_type) {
         case DFT_PROCESS_FRAME:
             if (task->do_ioproc) {
@@ -395,9 +395,11 @@
     }
 }
 
-static int init_model_ov(OVModel *ov_model, const char *input_name, const char *output_name)
+static int init_model_ov(OVModel *ov_model, const DNNExecBaseParams *exec_params)
 {
     int ret = 0;
+    const char* input_name = exec_params->input_name;
+    const char* output_name = exec_params->output_names[0];
     OVContext *ctx = &ov_model->ctx;
     IEStatusCode status;
     ie_available_devices_t a_dev;
@@ -402,8 +505,16 @@ static int init_model_ov(OVModel *ov_model, const char *input_name, const char *
             goto err;
         }
     }
-
-    status = ie_core_load_network(ov_model->core, ov_model->network, ctx->options.device_type, &config, &ov_model->exe_network);
+    if (exec_params->in_frame->format == AV_PIX_FMT_VAAPI) {
+#if CONFIG_VAAPI
+        ret = load_network_vaapi(ov_model, exec_params->in_frame, input_name);
+        if (ret != 0) {
+            av_log(ctx, AV_LOG_ERROR, "Failed to load OpenVINO model network in IGPU\n");
+            goto err;
+        }
+#endif
+    } else
+        status = ie_core_load_network(ov_model->core, ov_model->network, ctx->options.device_type, &config, &ov_model->exe_network);
     if (status != OK) {
         av_log(ctx, AV_LOG_ERROR, "Failed to load OpenVINO model network\n");
         status = ie_core_get_available_devices(ov_model->core, &a_dev);
@@ -726,11 +837,19 @@ static int get_output_ov(void *model, const char *input_name, int input_width, i
     }
 
     if (!ov_model->exe_network) {
-        ret = init_model_ov(ov_model, input_name, output_name);
+        AVFrame *dummy_frame = av_frame_alloc();
+        if (ov_model->model->filter_ctx->hw_device_ctx)
+            dummy_frame->format = AV_PIX_FMT_VAAPI;
+        dummy_frame->height = input_height;
+        dummy_frame->width = input_width;
+        exec_params.in_frame = dummy_frame;
+        ret = init_model_ov(ov_model, &exec_params);
         if (ret != 0) {
+            av_frame_free(&dummy_frame);
             av_log(ctx, AV_LOG_ERROR, "Failed init OpenVINO exectuable network or inference request\n");
             return ret;
         }
+        av_frame_free(&dummy_frame);
     }
 
     ret = ff_dnn_fill_gettingoutput_task(&task, &exec_params, ov_model, input_height, input_width, ctx);
@@ -863,7 +982,7 @@ static int dnn_execute_model_ov(const DNNModel *model, DNNExecBaseParams *exec_p
     }
 
     if (!ov_model->exe_network) {
-        ret = init_model_ov(ov_model, exec_params->input_name, exec_params->output_names[0]);
+        ret = init_model_ov(ov_model, exec_params);
         if (ret != 0) {
             av_log(ctx, AV_LOG_ERROR, "Failed init OpenVINO exectuable network or inference request\n");
             return ret;
-- 
2.34.1

